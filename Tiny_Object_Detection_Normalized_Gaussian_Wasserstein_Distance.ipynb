{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJxJHruNLb7Y"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/open-mmlab/mmdetection/blob/master/demo/MMDet_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGYwt_UjIrqp"
      },
      "source": [
        "# Tiny Object Detection : Normalized Gaussian Wasserstein Distance (NWD)\n",
        "\n",
        "This is an user implementation of Normalized Gaussian Wasserstein Distance for Tiny Object Detection(under review, https://arxiv.org/abs/2110.13389). This implementation includes \n",
        "\n",
        "- train Faster R-CNN on VisDrone2019 and AI-TOD using NWD.\n",
        "\n",
        "Let's start!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi4LPmsR66sy",
        "outputId": "5fd36491-1858-48ee-c4ce-18a5b7e61109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkGnB9WyHSXB",
        "outputId": "e1e27834-cbae-4656-cab2-100292a101db"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.5.1+cu101 in /usr/local/lib/python3.7/dist-packages (1.5.1+cu101)\n",
            "Requirement already satisfied: torchvision==0.6.1+cu101 in /usr/local/lib/python3.7/dist-packages (0.6.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu101/torch1.5.0/index.html\n",
            "Requirement already satisfied: mmcv-full in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.19.5)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (0.31.0)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (2.4.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (4.1.2.30)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full) (3.0.6)\n",
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 22371, done.\u001b[K\n",
            "remote: Total 22371 (delta 0), reused 0 (delta 0), pack-reused 22371\u001b[K\n",
            "Receiving objects: 100% (22371/22371), 25.47 MiB | 31.96 MiB/s, done.\n",
            "Resolving deltas: 100% (15659/15659), done.\n",
            "/content/mmdetection/mmdetection\n",
            "Obtaining file:///content/mmdetection/mmdetection\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet==2.19.1) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet==2.19.1) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet==2.19.1) (1.15.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from mmdet==2.19.1) (3.1.10)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet==2.19.1) (2.0.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.19.1) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.19.1) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.19.1) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.19.1) (2.8.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools->mmdet==2.19.1) (0.29.24)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->mmdet==2.19.1) (57.4.0)\n",
            "Installing collected packages: mmdet\n",
            "  Attempting uninstall: mmdet\n",
            "    Found existing installation: mmdet 2.19.1\n",
            "    Can't uninstall 'mmdet'. No files were found to uninstall.\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-2.19.1\n",
            "Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.7/dist-packages (7.0.0)\n"
          ]
        }
      ],
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "# it may take some time\n",
        "!pip install -U torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install mmcv-full thus we could use CUDA operators\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.5.0/index.html\n",
        "\n",
        "# Install mmdetection\n",
        "!rm -rf mmdetection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "# install Pillow 7.0.0 back in order to avoid bug in colab\n",
        "# you can ignore when restart rutime warning appear\n",
        "!pip install Pillow==7.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hD0mmMixT0p",
        "outputId": "9e5d7e0b-d4e7-4506-e660-974e0f5409da"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.5.1+cu101 True\n",
            "2.19.1\n",
            "10.1\n",
            "GCC 7.3\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "from glob import glob\n",
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E73y5Lru-wBx"
      },
      "source": [
        "### Dataset-1 : VisDrone2019"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHnw5Q_nARXq"
      },
      "outputs": [],
      "source": [
        "# If you have AI-TOD datset in your Google Drive, \n",
        "# simply connect to the Google Drive folder \n",
        "\n",
        "download_visdrone = False\n",
        "if download_visdrone :\n",
        "  # download, decompress the data\n",
        "  # not completed yet.. \n",
        "  !wget https://drive.google.com/file/d/1a2oHjcEcwXP8oUF95qiwrqzACb2YlUhn/view?usp=sharing\n",
        "else: \n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive/')\n",
        "  data_root_dir = '/content/drive/MyDrive/dataset/#bench_marks/VisDrone2019' # put your path to visdrone2019\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2BwF8OT8Yzh"
      },
      "outputs": [],
      "source": [
        "# directory names for train, val and test set \n",
        "train_dir_name = 'VisDrone2019-DET-train'\n",
        "val_dir_name = 'VisDrone2019-DET-val'\n",
        "test_dir_name = 'VisDrone2019-DET-test-dev' # sample test images with ground truth \n",
        "\n",
        "train_dir = os.path.join(data_root_dir, train_dir_name)\n",
        "val_dir = os.path.join(data_root_dir, val_dir_name)\n",
        "test_dir = os.path.join(data_root_dir, test_dir_name)\n",
        "\n",
        "train_img_list = glob(os.path.join(train_dir, 'images', \"*.jpg\"))\n",
        "val_img_list = glob(os.path.join(val_dir, 'images', \"*.jpg\"))\n",
        "test_img_list = glob(os.path.join(test_dir, 'images', \"*.jpg\"))\n",
        "\n",
        "train_ann_list = glob(os.path.join(train_dir, 'annotations', \"*.txt\"))\n",
        "val_ann_list = glob(os.path.join(val_dir, 'annotations', \"*.txt\"))\n",
        "test_ann_list = glob(os.path.join(test_dir, 'annotations', \"*.txt\"))\n",
        "\n",
        "print(\"Num of train images: {} \".format(len(train_img_list)))\n",
        "print(\"Num of validation images: {} \".format(len(val_img_list)))\n",
        "print(\"Num of test-dev images: {} \".format(len(test_img_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnQQqzOWzE91"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the dataset image\n",
        "import mmcv\n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "\n",
        "# img_idx = 0 # set specific image index \n",
        "img_idx = random.randint(0, len(train_img_list)-1)\n",
        "\n",
        "img = mmcv.imread(train_img_list[img_idx])\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(mmcv.bgr2rgb(img))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA1pFg-FeO3l"
      },
      "source": [
        "According to the VisDrone's documentation, the first four columns includes bbox information, and the 5th to 8th columns indicates score, object category, truncation and occlusion respectively. We need to read annotations of each image and convert them into middle format MMDetection accept is as below:\n",
        "\n",
        "```python\n",
        "[ <bbox_left>,<bbox_top>,<bbox_width>,<bbox_height>,<score>,<object_category>,<truncation>,<occlusion> ]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiPogvGZBS2b"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the dataset annotation format\n",
        "\n",
        "# img_idx = 0 # set specific image index \n",
        "ann_idx = random.randint(0, len(train_img_list)-1)\n",
        "\n",
        "ann_txt  = mmcv.list_from_file(train_ann_list[ann_idx]) # read a text file to list \n",
        "\n",
        "# please refer to annotation style at VisDrone2019 hompage : \"http://aiskyeye.com/evaluate/results-format_2021/\"\n",
        "\n",
        "print('<bbox_left>,<bbox_top>,<bbox_width>,<bbox_height>,<score>,<object_category>,<truncation>,<occlusion>')\n",
        "print(ann_txt[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0avp4P1DG0AI"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import os.path as osp\n",
        "\n",
        "import mmcv\n",
        "import numpy as np\n",
        "\n",
        "from mmdet.datasets.builder import DATASETS\n",
        "from mmdet.datasets.custom import CustomDataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "@DATASETS.register_module()\n",
        "class VisDrone2019Dataset(CustomDataset):\n",
        "\n",
        "    \"\"\"\n",
        "    The object category indicates the type of annotated object, \n",
        "    (i.e., ignored regions  (0), pedestrian (1), people (2), bicycle (3), \n",
        "            car             (4), van        (5), truck  (6), tricycle (7),\n",
        "            awning-tricycle (8), bus        (9), motor (10), others (11))\n",
        "    \"\"\"\n",
        "\n",
        "    CLASSES = ('pedestrian', 'people', 'bicycle'\n",
        "               'car', 'van', 'truck', 'tricycle', 'awning-tricycle', \n",
        "               'bus', 'motor', 'others') # exclude ignored regions\n",
        "\n",
        "    def load_annotations(self, ann_file):\n",
        "        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
        "\n",
        "        data_infos = []\n",
        "        image_list = glob(osp.join(self.data_root, self.img_prefix, '*jpg'))\n",
        "        ann_dir = osp.join(self.data_root, self.ann_file)\n",
        "        \n",
        "\n",
        "        for image_dir in tqdm(image_list,  desc=\"Load annotations\") : \n",
        "            image = mmcv.imread(image_dir)\n",
        "            height, width = image.shape[:2]\n",
        "            filename = image_dir.split('/')[-1]\n",
        "\n",
        "            data_info = dict(filename=filename, width=width, height=height)\n",
        "\n",
        "            # load annotations\n",
        "            ann_txt = mmcv.list_from_file(osp.join(ann_dir, filename.replace('jpg', 'txt')))\n",
        "\n",
        "            contents = [line.strip().split(',') for line in ann_txt]\n",
        "            bbox_labels = [x[5] for x in contents]\n",
        "\n",
        "            bboxes = []\n",
        "            for content in contents : \n",
        "                x, y, w, h = content[0:4]\n",
        "                x, y, w, h = float(x), float(y), float(w), float(h)\n",
        "                bboxes.append([x, y, x+w, y+h])\n",
        "\n",
        "            gt_bboxes = []\n",
        "            gt_labels = []\n",
        "            gt_bboxes_ignore = []\n",
        "            gt_labels_ignore = []\n",
        "\n",
        "            # filter 'DontCare'\n",
        "            for bbox_label, bbox in zip(bbox_labels, bboxes):\n",
        "                if bbox_label == '0':\n",
        "                    gt_labels_ignore.append(-1)\n",
        "                    gt_bboxes_ignore.append(bbox)\n",
        "                else:\n",
        "                    gt_labels.append(int(bbox_label)-1)\n",
        "                    gt_bboxes.append(bbox)\n",
        "                    \n",
        "            data_anno = dict(\n",
        "                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
        "                labels=np.array(gt_labels, dtype=np.long),\n",
        "                bboxes_ignore=np.array(gt_bboxes_ignore,\n",
        "                                       dtype=np.float32).reshape(-1, 4),\n",
        "                labels_ignore=np.array(gt_labels_ignore, dtype=np.long))\n",
        "\n",
        "            data_info.update(ann=data_anno)\n",
        "            data_infos.append(data_info)\n",
        "\n",
        "        return data_infos      "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IoU-Deviation Curve and NWD-Deviation Curve Comparison "
      ],
      "metadata": {
        "id": "0-EgGPgogCPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mmdet.core.bbox.iou_calculators.iou2d_calculator import bbox_overlaps\n",
        "\n",
        "\n",
        "def collect_iou_calculation(scales,dev_range, center_x, center_y, bbox1_size_factor, bbox2_size_factor):\n",
        "    bboxes1 = []\n",
        "    bboxes2 = []\n",
        "    overlap_cal_results = []\n",
        "    for scale_idx, scale in enumerate(scales):\n",
        "        width = bbox1_size_factor*scale \n",
        "        height = bbox1_size_factor*scale \n",
        "        x1, y1, x2, y2 = int(center_x-width/2), int(center_y-height/2), int(center_x+width/2), int(center_y+height/2)\n",
        "        bbox1 = [x1, y1, x2, y2]\n",
        "\n",
        "        bboxes1.append(bbox1)\n",
        "        bboxes2.append([])\n",
        "\n",
        "        for deviation in np.arange(dev_range[0], dev_range[-1]):\n",
        "            width = bbox2_size_factor*scale \n",
        "            height = bbox2_size_factor*scale \n",
        "            x1, y1, x2, y2 = int(center_x-width/2), int(center_y-height/2), int(center_x+width/2), int(center_y+height/2)\n",
        "            bbox2 =  [x1+deviation, y1+deviation, x2+deviation, y2+deviation]\n",
        "            bboxes2[scale_idx].append(bbox2)\n",
        "        \n",
        "        bbox1_tensor = torch.FloatTensor([bbox1])\n",
        "        bboxes2_tensor = torch.FloatTensor(bboxes2[scale_idx])\n",
        "        \n",
        "\n",
        "        overlap_cal_results.append(bbox_overlaps(bbox1_tensor, bboxes2_tensor)[0])\n",
        "\n",
        "    return overlap_cal_results"
      ],
      "metadata": {
        "id": "6O2USewrtOnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import wasserstein_distance\n",
        "from numpy.linalg import norm \n",
        "\n",
        "\n",
        "def collect_nwd_calculation(scales, dev_range, center_x, center_y, bbox1_size_factor, bbox2_size_factor, c=1):\n",
        "    bboxes1 = []\n",
        "    bboxes2 = []\n",
        "    overlap_cal_results = []\n",
        "    for scale_idx, scale in enumerate(scales):\n",
        "        overlap_cal_result = []\n",
        "        width = bbox1_size_factor*scale \n",
        "        height = bbox1_size_factor*scale \n",
        "        bbox1 = [center_x, center_y, width/2, height/2]\n",
        "\n",
        "        for deviation in np.arange(dev_range[0], dev_range[-1]):\n",
        "            width = bbox2_size_factor*scale \n",
        "            height = bbox2_size_factor*scale \n",
        "            bbox2 =  [center_x+deviation, center_y+deviation, width/2, height/2]\n",
        "            w_dist = wasserstein_distance(bbox1, bbox2)\n",
        "            # w_dist = norm(np.array([bbox1, bbox2]).T, ord=2)\n",
        "            nwd = np.exp(-np.sqrt(w_dist**2)/c)\n",
        "            overlap_cal_result.append(nwd)\n",
        "\n",
        "\n",
        "        overlap_cal_results.append(overlap_cal_result)\n",
        "\n",
        "    return overlap_cal_results"
      ],
      "metadata": {
        "id": "5HKqZ0XwihdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "center_x, center_y = 256, 256\n",
        "bbox1_size_factor = 1\n",
        "bbox2_size_factor = [1, 0.5]\n",
        "scales = [4, 12, 32, 48]\n",
        "dev_range = [-30, 30]\n",
        "\n",
        "overlap_cal_results_0 = collect_iou_calculation(scales,dev_range, center_x, center_y, bbox1_size_factor, bbox2_size_factor[0])\n",
        "overlap_cal_results_1 = collect_iou_calculation(scales,dev_range, center_x, center_y, bbox1_size_factor, bbox2_size_factor[1])\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "for result in overlap_cal_results_0 : \n",
        "    axs[0].plot(np.arange(dev_range[0], dev_range[1]), result, 'o--')\n",
        "    axs[0].set_xlabel('Deviation', fontsize=15)\n",
        "    axs[0].set_ylabel('IoU', fontsize=15)\n",
        "    axs[0].set_title('IoU-Deviation Curve : same size', fontsize=15)\n",
        "    axs[0].set_ylim(0, 1.0)\n",
        "\n",
        "\n",
        "for result in overlap_cal_results_1 : \n",
        "    axs[1].plot(np.arange(dev_range[0], dev_range[1]), result, 'o--')\n",
        "    axs[1].set_xlabel('Deviation', fontsize=15)\n",
        "    axs[1].set_ylabel('IoU', fontsize=15)\n",
        "    axs[1].set_title('IoU-Deviation Curve : 1/2 size', fontsize=15)\n",
        "    axs[1].set_ylim(0, 0.5)"
      ],
      "metadata": {
        "id": "tIcSPoN0gWbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "center_x, center_y = 256, 256\n",
        "bbox1_size_factor = 1\n",
        "bbox2_size_factor = [1, 0.5]\n",
        "scales = [4, 12, 32, 48]\n",
        "dev_range = [-30, 30]\n",
        "c = 4\n",
        "overlap_cal_results_0 = collect_nwd_calculation(scales,dev_range, center_x, center_y, bbox1_size_factor, bbox2_size_factor[0], c=c)\n",
        "overlap_cal_results_1 = collect_nwd_calculation(scales,dev_range, center_x, center_y, bbox1_size_factor, bbox2_size_factor[1], c=c)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "for result in overlap_cal_results_0 : \n",
        "    axs[0].plot(np.arange(dev_range[0], dev_range[1]), result, 'o--')\n",
        "    axs[0].set_xlabel('Deviation', fontsize=15)\n",
        "    axs[0].set_ylabel('NWD', fontsize=15)\n",
        "    axs[0].set_title('NWD-Deviation Curve : same size', fontsize=15)\n",
        "    axs[0].set_ylim(0, 1.0)\n",
        "\n",
        "\n",
        "for result in overlap_cal_results_1 : \n",
        "    axs[1].plot(np.arange(dev_range[0], dev_range[1]), result, 'o--')\n",
        "    axs[1].set_xlabel('Deviation', fontsize=15)\n",
        "    axs[1].set_ylabel('NWD', fontsize=15)\n",
        "    axs[1].set_title('NWD-Deviation Curve : 1/2 size', fontsize=15)\n",
        "    axs[1].set_ylim(0, 1.0)"
      ],
      "metadata": {
        "id": "KUg8YrLfjXbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OQ0Xmi9eHvk"
      },
      "outputs": [],
      "source": [
        "# NWD-based label assginment \n",
        "\n",
        "# mmdetection/mmdet/core/bbox/assigners/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NWD-based NMS \n",
        "# https://github.com/open-mmlab/mmcv/blob/master/mmcv/ops/nms.py\n",
        "\n"
      ],
      "metadata": {
        "id": "1tK86Q_kdXLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NWD-based regression loss \n",
        "# mmdetection/mmdet/models/losses/"
      ],
      "metadata": {
        "id": "fhi_TxVndXYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwqJOpBe-bMj"
      },
      "source": [
        "### Modify the config\n",
        "\n",
        "In the next step, we need to modify the config for the training.\n",
        "To accelerate the process, we finetune a detector using a pre-trained detector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hamZrlnH-YDD"
      },
      "outputs": [],
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile('./configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUbwD8uV0PR8"
      },
      "outputs": [],
      "source": [
        "from mmdet.apis import set_random_seed\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'VisDrone2019Dataset'\n",
        "cfg.data_root = data_root_dir\n",
        "\n",
        "cfg.data.test.type = 'VisDrone2019Dataset'\n",
        "cfg.data.test.data_root = '{}/{}/'.format(data_root_dir, test_dir_name) \n",
        "cfg.data.test.ann_file = 'annotations'\n",
        "cfg.data.test.img_prefix = 'images'\n",
        "\n",
        "cfg.data.train.type = 'VisDrone2019Dataset'\n",
        "cfg.data.train.data_root = '{}/{}/'.format(data_root_dir, train_dir_name) \n",
        "cfg.data.train.ann_file = 'annotations'\n",
        "cfg.data.train.img_prefix = 'images'\n",
        "\n",
        "cfg.data.val.type = 'VisDrone2019Dataset'\n",
        "cfg.data.val.data_root = '{}/{}/'.format(data_root_dir, val_dir_name) \n",
        "cfg.data.val.ann_file = 'annotations'\n",
        "cfg.data.val.img_prefix = 'images'\n",
        "\n",
        "# modify num classes of the model in box head\n",
        "cfg.model.roi_head.bbox_head.num_classes = 11 # exclude ignored regions\n",
        "\n",
        "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
        "# use the mask branch\n",
        "cfg.load_from = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.optimizer.lr = 0.02 / 8\n",
        "cfg.lr_config.warmup = None\n",
        "cfg.log_config.interval = 500\n",
        "\n",
        "# Change the evaluation metric since we use customized dataset.\n",
        "cfg.evaluation.metric = 'mAP'\n",
        "# We can set the evaluation interval to reduce the evaluation times\n",
        "cfg.evaluation.interval = 1\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 12\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "\n",
        "# We can initialize the logger for training and have a look\n",
        "# at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "111W_oZV_3wa"
      },
      "source": [
        "### Train a new detector\n",
        "\n",
        "Finally, lets initialize the dataset and detector, then train a new detector!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60qOrU4IaFmr"
      },
      "outputs": [],
      "source": [
        "# download checkpoint file \n",
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth \\\n",
        "      -O checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WBWHu010PN3"
      },
      "outputs": [],
      "source": [
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)] # should take a long time if google drive is used...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5fmdtQxa89M"
      },
      "outputs": [],
      "source": [
        "# Build the detector\n",
        "model = build_detector(\n",
        "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
        "# Add an attribute for visualization convenience\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_detector(model, datasets, cfg, distributed=False, validate=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_vYQF5K2NqqI"
      ],
      "name": "Tiny Object Detection : Normalized Gaussian Wasserstein Distance.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}